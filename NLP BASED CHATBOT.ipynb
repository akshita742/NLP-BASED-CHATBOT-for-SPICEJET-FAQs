{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6b4d5a-356d-476b-bdfb-b44fa9ec0e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup ready\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, glob, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from joblib import dump, load\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "ARTIFACT_DIR = \"./artifacts\"\n",
    "BACKUP_DIR   = \"./backups\"\n",
    "EDA_DIR      = \"./eda_exports\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "os.makedirs(EDA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"✅ Setup ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49ed6347-81c5-4e3d-a94d-dd774b4111ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/akshitaantil/Desktop/Spicejet ALL FAQ.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH  = os.path.expanduser(\"~/Desktop/Spicejet ALL FAQ.csv\")\n",
    "XLSX_PATH = os.path.expanduser(\"~/Desktop/Spicejet ALL FAQ.xlsx\")\n",
    "\n",
    "if   os.path.exists(CSV_PATH):  file_path = CSV_PATH\n",
    "elif os.path.exists(XLSX_PATH): file_path = XLSX_PATH\n",
    "else:\n",
    "    # fuzzy search fallback\n",
    "    matches = glob.glob(os.path.expanduser(\"~/Desktop/Spicejet*FAQ.*\"))\n",
    "    file_path = matches[0] if matches else None\n",
    "\n",
    "assert file_path is not None, \"❌ File not found on Desktop.\"\n",
    "file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6dd4e6-d844-4e75-ad4e-39b81f6d924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Raw backup saved: ./backups/raw_backup.csv Shape: (195, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Domestic/international</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>What is it like to fly with SpiceJet ?</td>\n",
       "      <td>Flying with SpiceJet is FUN, AFFORDABLE &amp; EXCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Does SpiceJet provide any food or drinks onboard?</td>\n",
       "      <td>Variety of hot meals, sandwiches, chef's choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Where does SpiceJet fly to?</td>\n",
       "      <td>SpiceJet connects you to wide network of desti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>What type of aircraft does SpiceJet fly?</td>\n",
       "      <td>SpiceJet operates a fleet of Boeing (B737-700,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>When will SpiceJet be flying to new destinations?</td>\n",
       "      <td>SpiceJetâ€™s aim is to provide affordable effi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>What if I just want to obtain flights schedule...</td>\n",
       "      <td>Passengers may view latest flight schedule fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Do I need any documents to enter the airport?</td>\n",
       "      <td>Yes, you would need your flight itinerary and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>How do I check-in for the flight?</td>\n",
       "      <td>For a swift airport experience and to avoid po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>What valid ID proof would be accepted at the a...</td>\n",
       "      <td>All Foreign Nationals/Non-Indian Nationals/NRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>General</td>\n",
       "      <td>general_faq</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>Does SpiceJet offer connections to other airli...</td>\n",
       "      <td>No, SpiceJet does not offer connections to oth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category       Intent Domestic/international  \\\n",
       "0  General  general_faq               Domestic   \n",
       "1  General  general_faq               Domestic   \n",
       "2  General  general_faq               Domestic   \n",
       "3  General  general_faq               Domestic   \n",
       "4  General  general_faq               Domestic   \n",
       "5  General  general_faq               Domestic   \n",
       "6  General  general_faq               Domestic   \n",
       "7  General  general_faq               Domestic   \n",
       "8  General  general_faq               Domestic   \n",
       "9  General  general_faq               Domestic   \n",
       "\n",
       "                                            Question  \\\n",
       "0             What is it like to fly with SpiceJet ?   \n",
       "1  Does SpiceJet provide any food or drinks onboard?   \n",
       "2                        Where does SpiceJet fly to?   \n",
       "3           What type of aircraft does SpiceJet fly?   \n",
       "4  When will SpiceJet be flying to new destinations?   \n",
       "5  What if I just want to obtain flights schedule...   \n",
       "6      Do I need any documents to enter the airport?   \n",
       "7                  How do I check-in for the flight?   \n",
       "8  What valid ID proof would be accepted at the a...   \n",
       "9  Does SpiceJet offer connections to other airli...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Flying with SpiceJet is FUN, AFFORDABLE & EXCI...  \n",
       "1  Variety of hot meals, sandwiches, chef's choic...  \n",
       "2  SpiceJet connects you to wide network of desti...  \n",
       "3  SpiceJet operates a fleet of Boeing (B737-700,...  \n",
       "4  SpiceJetâ€™s aim is to provide affordable effi...  \n",
       "5  Passengers may view latest flight schedule fro...  \n",
       "6  Yes, you would need your flight itinerary and ...  \n",
       "7  For a swift airport experience and to avoid po...  \n",
       "8  All Foreign Nationals/Non-Indian Nationals/NRI...  \n",
       "9  No, SpiceJet does not offer connections to oth...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = os.path.splitext(file_path)[1].lower()\n",
    "if ext == \".csv\":\n",
    "    df_raw = pd.read_csv(file_path, encoding=\"utf-8-sig\")\n",
    "elif ext in (\".xlsx\", \".xls\"):\n",
    "    df_raw = pd.read_excel(file_path)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported type: {ext}\")\n",
    "\n",
    "backup_path = os.path.join(BACKUP_DIR, \"raw_backup.csv\")\n",
    "df_raw.to_csv(backup_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Raw backup saved:\", backup_path, \"Shape:\", df_raw.shape)\n",
    "df_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1203e3fb-ef45-498c-aa62-7d6ddb68d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using columns: ['question', 'answer', 'intent'] Rows: 195\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is it like to fly with SpiceJet ?</td>\n",
       "      <td>Flying with SpiceJet is FUN, AFFORDABLE &amp; EXCI...</td>\n",
       "      <td>general_faq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does SpiceJet provide any food or drinks onboard?</td>\n",
       "      <td>Variety of hot meals, sandwiches, chef's choic...</td>\n",
       "      <td>general_faq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where does SpiceJet fly to?</td>\n",
       "      <td>SpiceJet connects you to wide network of desti...</td>\n",
       "      <td>general_faq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What type of aircraft does SpiceJet fly?</td>\n",
       "      <td>SpiceJet operates a fleet of Boeing (B737-700,...</td>\n",
       "      <td>general_faq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When will SpiceJet be flying to new destinations?</td>\n",
       "      <td>SpiceJetâ€™s aim is to provide affordable effi...</td>\n",
       "      <td>general_faq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What is it like to fly with SpiceJet ?   \n",
       "1  Does SpiceJet provide any food or drinks onboard?   \n",
       "2                        Where does SpiceJet fly to?   \n",
       "3           What type of aircraft does SpiceJet fly?   \n",
       "4  When will SpiceJet be flying to new destinations?   \n",
       "\n",
       "                                              answer       intent  \n",
       "0  Flying with SpiceJet is FUN, AFFORDABLE & EXCI...  general_faq  \n",
       "1  Variety of hot meals, sandwiches, chef's choic...  general_faq  \n",
       "2  SpiceJet connects you to wide network of desti...  general_faq  \n",
       "3  SpiceJet operates a fleet of Boeing (B737-700,...  general_faq  \n",
       "4  SpiceJetâ€™s aim is to provide affordable effi...  general_faq  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "cands = {\n",
    "    \"question\": [\"question\",\"Question\",\"questions\",\"query\",\"Query\",\"Q\"],\n",
    "    \"answer\":   [\"answer\",\"Answer\",\"answers\",\"response\",\"Response\",\"A\",\"Ans\"],\n",
    "    \"intent\":   [\"intent\",\"Intent\",\"label\",\"Label\",\"class\",\"Class\",\"CATEGORY\",\"Category\"]\n",
    "}\n",
    "def pick(name_list, cols): \n",
    "    for c in name_list:\n",
    "        if c in cols: return c\n",
    "\n",
    "cols = set(df.columns)\n",
    "q_col = pick(cands[\"question\"], cols)\n",
    "a_col = pick(cands[\"answer\"], cols)\n",
    "i_col = pick(cands[\"intent\"], cols)  # may be None\n",
    "\n",
    "assert q_col and a_col, \"❌ Need at least question & answer columns.\"\n",
    "\n",
    "keep = [q_col, a_col] + ([i_col] if i_col else [])\n",
    "df = df[keep].copy()\n",
    "df.columns = [\"question\",\"answer\"] + ([\"intent\"] if i_col else [])\n",
    "print(\"✅ Using columns:\", df.columns.tolist(), \"Rows:\", len(df))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34acb54f-f4f6-4c99-ab79-6966a75235ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EDA saved to ./eda_exports/eda_summary.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rows': 195,\n",
       " 'columns': ['question', 'answer', 'intent'],\n",
       " 'null_counts': {'question': 0, 'answer': 0, 'intent': 104},\n",
       " 'question_len': {'min': 17, 'max': 181, 'mean': 55.0974358974359},\n",
       " 'answer_len': {'min': 4, 'max': 2151, 'mean': 445.05128205128204},\n",
       " 'n_classes': 3,\n",
       " 'top_classes': {'nan': 104,\n",
       "  'booking_faq': 43,\n",
       "  'general_faq': 31,\n",
       "  'specialAssistance_faq': 17}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda = {\n",
    "    \"rows\": len(df),\n",
    "    \"columns\": df.columns.tolist(),\n",
    "    \"null_counts\": df.isnull().sum().to_dict(),\n",
    "    \"question_len\": {\n",
    "        \"min\": int(df[\"question\"].astype(str).str.len().min()),\n",
    "        \"max\": int(df[\"question\"].astype(str).str.len().max()),\n",
    "        \"mean\": float(df[\"question\"].astype(str).str.len().mean())\n",
    "    },\n",
    "    \"answer_len\": {\n",
    "        \"min\": int(df[\"answer\"].astype(str).str.len().min()),\n",
    "        \"max\": int(df[\"answer\"].astype(str).str.len().max()),\n",
    "        \"mean\": float(df[\"answer\"].astype(str).str.len().mean())\n",
    "    }\n",
    "}\n",
    "if \"intent\" in df.columns:\n",
    "    eda[\"n_classes\"] = int(df[\"intent\"].nunique())\n",
    "    eda[\"top_classes\"] = df[\"intent\"].astype(str).value_counts().head(10).to_dict()\n",
    "\n",
    "eda_path = os.path.join(EDA_DIR, \"eda_summary.json\")\n",
    "with open(eda_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(eda, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ EDA saved to\", eda_path)\n",
    "eda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d8b71e-b7a4-44a3-aa76-ab3a1b9eb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean columns added.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_clean</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is it like to fly with SpiceJet ?</td>\n",
       "      <td>what is it like to fly with spicejet</td>\n",
       "      <td>Flying with SpiceJet is FUN, AFFORDABLE &amp; EXCI...</td>\n",
       "      <td>flying with spicejet is fun affordable excitin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does SpiceJet provide any food or drinks onboard?</td>\n",
       "      <td>does spicejet provide any food or drinks onboard</td>\n",
       "      <td>Variety of hot meals, sandwiches, chef's choic...</td>\n",
       "      <td>variety of hot meals sandwiches chef s choices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where does SpiceJet fly to?</td>\n",
       "      <td>where does spicejet fly to</td>\n",
       "      <td>SpiceJet connects you to wide network of desti...</td>\n",
       "      <td>spicejet connects you to wide network of desti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What type of aircraft does SpiceJet fly?</td>\n",
       "      <td>what type of aircraft does spicejet fly</td>\n",
       "      <td>SpiceJet operates a fleet of Boeing (B737-700,...</td>\n",
       "      <td>spicejet operates a fleet of boeing b737-700 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When will SpiceJet be flying to new destinations?</td>\n",
       "      <td>when will spicejet be flying to new destinations</td>\n",
       "      <td>SpiceJetâ€™s aim is to provide affordable effi...</td>\n",
       "      <td>spicejetâ s aim is to provide affordable effic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             What is it like to fly with SpiceJet ?   \n",
       "1  Does SpiceJet provide any food or drinks onboard?   \n",
       "2                        Where does SpiceJet fly to?   \n",
       "3           What type of aircraft does SpiceJet fly?   \n",
       "4  When will SpiceJet be flying to new destinations?   \n",
       "\n",
       "                                     question_clean  \\\n",
       "0              what is it like to fly with spicejet   \n",
       "1  does spicejet provide any food or drinks onboard   \n",
       "2                        where does spicejet fly to   \n",
       "3           what type of aircraft does spicejet fly   \n",
       "4  when will spicejet be flying to new destinations   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Flying with SpiceJet is FUN, AFFORDABLE & EXCI...   \n",
       "1  Variety of hot meals, sandwiches, chef's choic...   \n",
       "2  SpiceJet connects you to wide network of desti...   \n",
       "3  SpiceJet operates a fleet of Boeing (B737-700,...   \n",
       "4  SpiceJetâ€™s aim is to provide affordable effi...   \n",
       "\n",
       "                                        answer_clean  \n",
       "0  flying with spicejet is fun affordable excitin...  \n",
       "1  variety of hot meals sandwiches chef s choices...  \n",
       "2  spicejet connects you to wide network of desti...  \n",
       "3  spicejet operates a fleet of boeing b737-700 b...  \n",
       "4  spicejetâ s aim is to provide affordable effic...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\"[^\\w\\s./%₹$-]\", \" \", s)  # keep useful symbols\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"question_clean\"] = df[\"question\"].map(normalize_text)\n",
    "df[\"answer_clean\"]   = df[\"answer\"].map(normalize_text)\n",
    "\n",
    "print(\"✅ Clean columns added.\")\n",
    "df[[\"question\",\"question_clean\",\"answer\",\"answer_clean\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4235699d-df79-4ae8-b3ed-9043d07117d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Intents ready. Classes: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "booking_faq              43\n",
       "general_faq              31\n",
       "specialAssistance_faq    17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"intent\" not in df.columns:\n",
    "    def canon_answer(s):\n",
    "        s = normalize_text(s)\n",
    "        s = re.sub(r\"\\b(spicejet|hello|dear customer|thanks|regards)\\b\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return s\n",
    "    canon = df[\"answer_clean\"].map(canon_answer)\n",
    "    mapping = {k:i for i,k in enumerate(sorted(canon.unique()))}\n",
    "    df[\"intent\"] = canon.map(lambda x: f\"intent_{mapping[x]:03d}\")\n",
    "\n",
    "print(\"✅ Intents ready. Classes:\", df[\"intent\"].nunique())\n",
    "df[\"intent\"].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad63cab2-7b04-40f3-b91d-c7436236345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Intents repaired. Total classes: 96\n",
      "Sample intents: ['general_faq', 'booking_faq', 'specialAssistance_faq', 'intent_from_answer_020', 'intent_from_answer_019', 'intent_from_answer_022', 'intent_from_answer_030', 'intent_from_answer_041', 'intent_from_answer_086', 'intent_from_answer_092']\n",
      "[Fold 1]  Acc=0.410  Macro-F1=0.147  Weighted-F1=0.458\n",
      "[Fold 2]  Acc=0.385  Macro-F1=0.127  Weighted-F1=0.427\n",
      "[Fold 3]  Acc=0.410  Macro-F1=0.177  Weighted-F1=0.451\n",
      "[Fold 4]  Acc=0.308  Macro-F1=0.131  Weighted-F1=0.370\n",
      "[Fold 5]  Acc=0.282  Macro-F1=0.126  Weighted-F1=0.350\n",
      "\n",
      "CV Summary: {\n",
      "  \"accuracy_mean\": 0.35897435897435903,\n",
      "  \"accuracy_std\": 0.05378506913693084,\n",
      "  \"f1_macro_mean\": 0.1416353562479818,\n",
      "  \"f1_macro_std\": 0.01928764179596957,\n",
      "  \"f1_weighted_mean\": 0.4113547588660711,\n",
      "  \"f1_weighted_std\": 0.04342863473040766,\n",
      "  \"per_fold\": [\n",
      "    {\n",
      "      \"fold\": 1,\n",
      "      \"accuracy\": 0.41025641025641024,\n",
      "      \"f1_macro\": 0.14679487179487177,\n",
      "      \"f1_weighted\": 0.45825115055884286\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 2,\n",
      "      \"accuracy\": 0.38461538461538464,\n",
      "      \"f1_macro\": 0.12745098039215688,\n",
      "      \"f1_weighted\": 0.426596279537456\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 3,\n",
      "      \"accuracy\": 0.41025641025641024,\n",
      "      \"f1_macro\": 0.1772357723577236,\n",
      "      \"f1_weighted\": 0.45128205128205134\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 4,\n",
      "      \"accuracy\": 0.3076923076923077,\n",
      "      \"f1_macro\": 0.13076923076923078,\n",
      "      \"f1_weighted\": 0.37021696252465486\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 5,\n",
      "      \"accuracy\": 0.28205128205128205,\n",
      "      \"f1_macro\": 0.12592592592592594,\n",
      "      \"f1_weighted\": 0.3504273504273504\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "✅ CV summary saved to artifacts/cv_summary.json\n"
     ]
    }
   ],
   "source": [
    "# --- PATCH: normalize/repair intents so they are all non-null strings ---\n",
    "\n",
    "import re\n",
    "def normalize_text(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\"[^\\w\\s./%₹$-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def canon_answer(s):\n",
    "    s = normalize_text(s)\n",
    "    s = re.sub(r\"\\b(spicejet|hello|dear customer|thanks|regards)\\b\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Ensure we have clean helper cols (won't overwrite originals)\n",
    "if \"answer_clean\" not in df.columns:\n",
    "    df[\"answer_clean\"] = df[\"answer\"].map(normalize_text)\n",
    "\n",
    "# 1) Find missing/empty intents\n",
    "if \"intent\" not in df.columns:\n",
    "    df[\"intent\"] = np.nan\n",
    "\n",
    "missing_mask = df[\"intent\"].isna() | (df[\"intent\"].astype(str).str.strip().isin([\"\", \"nan\", \"None\", \"NaN\"]))\n",
    "\n",
    "# 2) For only the missing ones, create pseudo-intents from their answers\n",
    "if missing_mask.any():\n",
    "    canon = df.loc[missing_mask, \"answer_clean\"].map(canon_answer)\n",
    "    # stable mapping only for the missing subset\n",
    "    mapping = {k:i for i,k in enumerate(sorted(canon.unique()))}\n",
    "    df.loc[missing_mask, \"intent\"] = canon.map(lambda x: f\"intent_from_answer_{mapping[x]:03d}\")\n",
    "\n",
    "# 3) Finally, force everything to string\n",
    "df[\"intent\"] = df[\"intent\"].astype(str)\n",
    "\n",
    "# 4) Safety checks\n",
    "assert not df[\"intent\"].isna().any(), \"There are still NaNs in intent — patch didn’t cover something.\"\n",
    "print(\"✅ Intents repaired. Total classes:\", df[\"intent\"].nunique())\n",
    "print(\"Sample intents:\", list(df[\"intent\"].unique())[:10])\n",
    "# ----------------------------\n",
    "# 📊 Cell 8 — 5-Fold Stratified Cross-Validation\n",
    "# ----------------------------\n",
    "# What/Why: \n",
    "# - Split into 5 equal folds (stratified = keeps intent balance in each fold)\n",
    "# - Train on 4 folds, test on 1, repeat 5 times\n",
    "# - Gives stable accuracy/F1 scores for small datasets like your 196-row SpiceJet data\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Make sure intents are strings (prevents float/string mix errors)\n",
    "df[\"intent\"] = df[\"intent\"].astype(str)\n",
    "\n",
    "X_all = df[\"question_clean\"].values\n",
    "y_all = df[\"intent\"].values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_stats = []\n",
    "for fold, (tr_idx, te_idx) in enumerate(skf.split(X_all, y_all), start=1):\n",
    "    X_tr, X_te = X_all[tr_idx], X_all[te_idx]\n",
    "    y_tr, y_te = y_all[tr_idx], y_all[te_idx]\n",
    "    \n",
    "    # Calculate balanced class weights for this fold\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    classes = np.unique(y_tr)\n",
    "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_tr)\n",
    "    cw = {c: w for c, w in zip(classes, class_weights)}\n",
    "    \n",
    "    # Train the pipeline\n",
    "    clf_pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.95)),\n",
    "        (\"clf\", LogisticRegression(max_iter=300, C=2.0, class_weight=cw))\n",
    "    ])\n",
    "    clf_pipeline.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict and score\n",
    "    y_pred = clf_pipeline.predict(X_te)\n",
    "    acc  = accuracy_score(y_te, y_pred)\n",
    "    f1_m = f1_score(y_te, y_pred, average=\"macro\")\n",
    "    f1_w = f1_score(y_te, y_pred, average=\"weighted\")\n",
    "    \n",
    "    fold_stats.append({\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_m,\n",
    "        \"f1_weighted\": f1_w\n",
    "    })\n",
    "    \n",
    "    print(f\"[Fold {fold}]  Acc={acc:.3f}  Macro-F1={f1_m:.3f}  Weighted-F1={f1_w:.3f}\")\n",
    "\n",
    "# Summarize across folds\n",
    "cv_summary = {\n",
    "    \"accuracy_mean\":  np.mean([d[\"accuracy\"] for d in fold_stats]),\n",
    "    \"accuracy_std\":   np.std([d[\"accuracy\"]  for d in fold_stats]),\n",
    "    \"f1_macro_mean\":  np.mean([d[\"f1_macro\"] for d in fold_stats]),\n",
    "    \"f1_macro_std\":   np.std([d[\"f1_macro\"]  for d in fold_stats]),\n",
    "    \"f1_weighted_mean\": np.mean([d[\"f1_weighted\"] for d in fold_stats]),\n",
    "    \"f1_weighted_std\":  np.std([d[\"f1_weighted\"]  for d in fold_stats]),\n",
    "    \"per_fold\": fold_stats\n",
    "}\n",
    "print(\"\\nCV Summary:\", json.dumps(cv_summary, indent=2))\n",
    "\n",
    "# Save for later\n",
    "with open(os.path.join(ARTIFACT_DIR, \"cv_summary.json\"), \"w\") as f:\n",
    "    json.dump(cv_summary, f, indent=2)\n",
    "print(\"✅ CV summary saved to artifacts/cv_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40292843-6709-4216-8997-64bfc27ce0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline defined\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_all = df[\"intent\"].values\n",
    "classes = np.unique(y_all)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_all)\n",
    "cw = {c:w for c,w in zip(classes, class_weights)}\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.95)),\n",
    "    (\"clf\",   LogisticRegression(max_iter=300, C=2.0, class_weight=cw))\n",
    "])\n",
    "\n",
    "print(\"✅ Pipeline defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd46b1d4-c909-4450-b88c-19257a12f4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1]  Acc=0.410  Macro-F1=0.147  Weighted-F1=0.458\n",
      "[Fold 2]  Acc=0.385  Macro-F1=0.127  Weighted-F1=0.427\n",
      "[Fold 3]  Acc=0.410  Macro-F1=0.177  Weighted-F1=0.451\n",
      "[Fold 4]  Acc=0.308  Macro-F1=0.131  Weighted-F1=0.370\n",
      "[Fold 5]  Acc=0.282  Macro-F1=0.126  Weighted-F1=0.350\n",
      "\n",
      "CV Summary: {\n",
      "  \"accuracy_mean\": 0.35897435897435903,\n",
      "  \"accuracy_std\": 0.05378506913693084,\n",
      "  \"f1_macro_mean\": 0.1416353562479818,\n",
      "  \"f1_macro_std\": 0.01928764179596957,\n",
      "  \"f1_weighted_mean\": 0.4113547588660711,\n",
      "  \"f1_weighted_std\": 0.04342863473040766,\n",
      "  \"per_fold\": [\n",
      "    {\n",
      "      \"fold\": 1,\n",
      "      \"accuracy\": 0.41025641025641024,\n",
      "      \"f1_macro\": 0.14679487179487177,\n",
      "      \"f1_weighted\": 0.45825115055884286\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 2,\n",
      "      \"accuracy\": 0.38461538461538464,\n",
      "      \"f1_macro\": 0.12745098039215688,\n",
      "      \"f1_weighted\": 0.426596279537456\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 3,\n",
      "      \"accuracy\": 0.41025641025641024,\n",
      "      \"f1_macro\": 0.1772357723577236,\n",
      "      \"f1_weighted\": 0.45128205128205134\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 4,\n",
      "      \"accuracy\": 0.3076923076923077,\n",
      "      \"f1_macro\": 0.13076923076923078,\n",
      "      \"f1_weighted\": 0.37021696252465486\n",
      "    },\n",
      "    {\n",
      "      \"fold\": 5,\n",
      "      \"accuracy\": 0.28205128205128205,\n",
      "      \"f1_macro\": 0.12592592592592594,\n",
      "      \"f1_weighted\": 0.3504273504273504\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "✅ CV summary saved to artifacts/cv_summary.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 📊 Cell 8 — 5-Fold Stratified Cross-Validation\n",
    "# ----------------------------\n",
    "# What/Why: \n",
    "# - Split into 5 equal folds (stratified = keeps intent balance in each fold)\n",
    "# - Train on 4 folds, test on 1, repeat 5 times\n",
    "# - Gives stable accuracy/F1 scores for small datasets like your 196-row SpiceJet data\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Make sure intents are strings (prevents float/string mix errors)\n",
    "df[\"intent\"] = df[\"intent\"].astype(str)\n",
    "\n",
    "X_all = df[\"question_clean\"].values\n",
    "y_all = df[\"intent\"].values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_stats = []\n",
    "for fold, (tr_idx, te_idx) in enumerate(skf.split(X_all, y_all), start=1):\n",
    "    X_tr, X_te = X_all[tr_idx], X_all[te_idx]\n",
    "    y_tr, y_te = y_all[tr_idx], y_all[te_idx]\n",
    "    \n",
    "    # Calculate balanced class weights for this fold\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    classes = np.unique(y_tr)\n",
    "    class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_tr)\n",
    "    cw = {c: w for c, w in zip(classes, class_weights)}\n",
    "    \n",
    "    # Train the pipeline\n",
    "    clf_pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.95)),\n",
    "        (\"clf\", LogisticRegression(max_iter=300, C=2.0, class_weight=cw))\n",
    "    ])\n",
    "    clf_pipeline.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predict and score\n",
    "    y_pred = clf_pipeline.predict(X_te)\n",
    "    acc  = accuracy_score(y_te, y_pred)\n",
    "    f1_m = f1_score(y_te, y_pred, average=\"macro\")\n",
    "    f1_w = f1_score(y_te, y_pred, average=\"weighted\")\n",
    "    \n",
    "    fold_stats.append({\n",
    "        \"fold\": fold,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_m,\n",
    "        \"f1_weighted\": f1_w\n",
    "    })\n",
    "    \n",
    "    print(f\"[Fold {fold}]  Acc={acc:.3f}  Macro-F1={f1_m:.3f}  Weighted-F1={f1_w:.3f}\")\n",
    "\n",
    "# Summarize across folds\n",
    "cv_summary = {\n",
    "    \"accuracy_mean\":  np.mean([d[\"accuracy\"] for d in fold_stats]),\n",
    "    \"accuracy_std\":   np.std([d[\"accuracy\"]  for d in fold_stats]),\n",
    "    \"f1_macro_mean\":  np.mean([d[\"f1_macro\"] for d in fold_stats]),\n",
    "    \"f1_macro_std\":   np.std([d[\"f1_macro\"]  for d in fold_stats]),\n",
    "    \"f1_weighted_mean\": np.mean([d[\"f1_weighted\"] for d in fold_stats]),\n",
    "    \"f1_weighted_std\":  np.std([d[\"f1_weighted\"]  for d in fold_stats]),\n",
    "    \"per_fold\": fold_stats\n",
    "}\n",
    "print(\"\\nCV Summary:\", json.dumps(cv_summary, indent=2))\n",
    "\n",
    "# Save for later\n",
    "with open(os.path.join(ARTIFACT_DIR, \"cv_summary.json\"), \"w\") as f:\n",
    "    json.dump(cv_summary, f, indent=2)\n",
    "print(\"✅ CV summary saved to artifacts/cv_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56dae895-7aa3-4785-8197-2e53cdcb3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final model trained on ALL data.\n",
      "• Classes learned: 96\n",
      "• Example check -> intent_from_answer_037\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# ✅ Cell 9 — Train FINAL model on ALL data\n",
    "# ----------------------------\n",
    "# What/Why:\n",
    "# - After 5-fold CV, we train one last time on the entire dataset (no holdout)\n",
    "# - Uses balanced class weights so rare intents matter\n",
    "# - Produces `clf_pipeline` that later cells (retrieval/router/saving) will use\n",
    "# ----------------------------\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Safety: keep intents as strings\n",
    "df[\"intent\"] = df[\"intent\"].astype(str)\n",
    "\n",
    "X_all = df[\"question_clean\"].values\n",
    "y_all = df[\"intent\"].values\n",
    "\n",
    "# Balanced class weights on full data\n",
    "classes_full = np.unique(y_all)\n",
    "class_weights_full = compute_class_weight(class_weight=\"balanced\",\n",
    "                                          classes=classes_full, y=y_all)\n",
    "cw_full = {c:w for c, w in zip(classes_full, class_weights_full)}\n",
    "\n",
    "# Define & fit the final pipeline\n",
    "clf_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.95)),\n",
    "    (\"clf\",   LogisticRegression(max_iter=300, C=2.0, class_weight=cw_full))\n",
    "])\n",
    "\n",
    "clf_pipeline.fit(X_all, y_all)\n",
    "\n",
    "print(\"✅ Final model trained on ALL data.\")\n",
    "print(\"• Classes learned:\", len(clf_pipeline.named_steps['clf'].classes_))\n",
    "print(\"• Example check ->\",\n",
    "      clf_pipeline.predict([\"how much luggage can I carry?\"])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3617463-8330-49e6-80b2-72a6168cea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieval index ready (char n-grams): KB size=195, TFIDF shape=(195, 3443)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 10 (Corrected) ---\n",
    "# Char n-gram retrieval for better matching on small queries, typos, and variants\n",
    "\n",
    "import re\n",
    "def _norm(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\"[^\\w\\s./%₹$-]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "# Use cleaned questions if present\n",
    "KB_Q = df[\"question_clean\"].tolist() if \"question_clean\" in df.columns else [_norm(x) for x in df[\"question\"].astype(str)]\n",
    "KB_A = df[\"answer\"].tolist()\n",
    "KB_I = df[\"intent\"].astype(str).tolist()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 🔁 Char n-grams (3,5) for robust matching\n",
    "retr_vectorizer = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)\n",
    "KB_TFIDF = retr_vectorizer.fit_transform(KB_Q)\n",
    "\n",
    "def cosine_topk(query: str, k: int = 3):\n",
    "    qv = retr_vectorizer.transform([_norm(query)])\n",
    "    sims = (qv @ KB_TFIDF.T).toarray().ravel()\n",
    "    top = np.argsort(-sims)[:k]\n",
    "    return sims[top], top\n",
    "\n",
    "print(f\"✅ Retrieval index ready (char n-grams): KB size={len(KB_Q)}, TFIDF shape={KB_TFIDF.shape}\")\n",
    "\n",
    "# --- Helper: retrieve_best ---\n",
    "def retrieve_best(query: str, k: int = 3):\n",
    "    sims, top_idx = cosine_topk(query, k)\n",
    "    hits = []\n",
    "    for idx, score in zip(top_idx, sims):\n",
    "        hits.append({\n",
    "            \"question\": KB_Q[idx],\n",
    "            \"answer\": KB_A[idx],\n",
    "            \"intent\": KB_I[idx],\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "    # Return: best_answer, best_intent, best_score, full_hits_list\n",
    "    return hits[0][\"answer\"], hits[0][\"intent\"], sims[0], hits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "602af48b-b1eb-4001-a17b-aa4278d09716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 11 (Corrected) ---\n",
    "INTENT_THRESHOLD = 0.35   # lowered from 0.50\n",
    "RETR_THRESHOLD   = 0.25   # lowered from 0.35\n",
    "TOPK_DEFAULT     = 3\n",
    "\n",
    "import re\n",
    "\n",
    "def route_query(question: str,\n",
    "                intent_threshold: float = INTENT_THRESHOLD,\n",
    "                retrieval_threshold: float = RETR_THRESHOLD,\n",
    "                method: str = \"hybrid\",\n",
    "                topk: int = TOPK_DEFAULT):\n",
    "\n",
    "    q = (question or \"\").strip().lower()\n",
    "    route, answer, pred_intent_for_eval = \"abstain\", None, None\n",
    "\n",
    "    # 1) Intent\n",
    "    try:\n",
    "        intent_label, intent_score = predict_intent(q)\n",
    "    except Exception:\n",
    "        intent_label, intent_score = None, 0.0\n",
    "\n",
    "    # 2) Retrieval\n",
    "    try:\n",
    "        best_ans, best_int, retrieval_score, ret_hits = retrieve_best(q, k=topk)\n",
    "    except Exception:\n",
    "        best_ans, best_int, retrieval_score, ret_hits = None, None, 0.0, []\n",
    "\n",
    "    # Helper: keyword overlap\n",
    "    def keyword_overlap(qtext, kbtext):\n",
    "        stop = {\"the\",\"a\",\"an\",\"is\",\"are\",\"am\",\"for\",\"to\",\"of\",\"in\",\"on\",\"with\",\"and\",\"or\",\n",
    "                \"can\",\"i\",\"me\",\"my\",\"what\",\"how\",\"do\",\"does\"}\n",
    "        q_words  = [w for w in re.findall(r\"[a-z0-9]+\", qtext) if w not in stop]\n",
    "        kb_words = [w for w in re.findall(r\"[a-z0-9]+\", kbtext) if w not in stop]\n",
    "        return len(set(q_words) & set(kb_words))\n",
    "\n",
    "    # Synonym expansion\n",
    "    def expand_query(qtext: str) -> str:\n",
    "        expansions = {\n",
    "            \"discount\": [\"offer\",\"promotion\",\"promo\",\"deal\",\"concession\",\"rebate\",\"sale\",\"fare cut\"],\n",
    "            \"discounts\": [\"offers\",\"promotions\",\"deals\"],\n",
    "            \"baggage\": [\"luggage\",\"bag\",\"bags\"],\n",
    "            \"luggage\": [\"baggage\",\"bag\",\"bags\"],\n",
    "            \"extra\": [\"additional\",\"excess\"],\n",
    "        }\n",
    "        words = qtext.split()\n",
    "        extra = []\n",
    "        for w in words:\n",
    "            extra += expansions.get(w, [])\n",
    "        return (qtext + \" \" + \" \".join(extra)).strip()\n",
    "\n",
    "    # Expanded retrieval\n",
    "    expanded_q = expand_query(q)\n",
    "    if expanded_q != q:\n",
    "        _, _, expanded_score, expanded_hits = retrieve_best(expanded_q, k=topk)\n",
    "    else:\n",
    "        expanded_score, expanded_hits = retrieval_score, ret_hits\n",
    "\n",
    "    # 3) Routing\n",
    "    if method == \"intent\":\n",
    "        if intent_score >= intent_threshold:\n",
    "            route = \"intent\"\n",
    "            pred_intent_for_eval = intent_label\n",
    "            subset = df[df[\"intent\"] == intent_label]\n",
    "            answer = subset[\"answer\"].mode().iloc[0] if len(subset) else None\n",
    "\n",
    "    elif method == \"retrieval\":\n",
    "        if expanded_score >= retrieval_threshold:\n",
    "            route = \"retrieval\"\n",
    "            pred_intent_for_eval = expanded_hits[0][\"intent\"] if expanded_hits else best_int\n",
    "            answer = expanded_hits[0][\"answer\"] if expanded_hits else best_ans\n",
    "\n",
    "    else:  # hybrid\n",
    "        if intent_score >= intent_threshold and intent_score >= expanded_score:\n",
    "            route = \"intent\"\n",
    "            pred_intent_for_eval = intent_label\n",
    "            subset = df[df[\"intent\"] == intent_label]\n",
    "            answer = subset[\"answer\"].mode().iloc[0] if len(subset) else None\n",
    "        elif expanded_score >= retrieval_threshold:\n",
    "            route = \"retrieval\"\n",
    "            pred_intent_for_eval = expanded_hits[0][\"intent\"] if expanded_hits else best_int\n",
    "            answer = expanded_hits[0][\"answer\"] if expanded_hits else best_ans\n",
    "        else:\n",
    "            # Low-confidence fallback\n",
    "            top1 = expanded_hits[0] if expanded_hits else (ret_hits[0] if ret_hits else None)\n",
    "            candidate = top1 or {}\n",
    "            candidate_q = candidate.get(\"question\", \"\")\n",
    "            overlap = keyword_overlap(q, candidate_q)\n",
    "            weak_score = candidate.get(\"score\", 0.0)\n",
    "\n",
    "            if overlap >= 1 and weak_score >= 0.15:\n",
    "                route = \"retrieval_low_conf\"\n",
    "                pred_intent_for_eval = candidate.get(\"intent\")\n",
    "                answer = \"(Low confidence) \" + candidate.get(\"answer\", \"\")\n",
    "\n",
    "    confidence = float(max(intent_score, expanded_score))\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"route\": route,\n",
    "        \"intent\": {\"label\": intent_label, \"score\": float(intent_score)},\n",
    "        \"retrieval\": {\"best_score\": float(expanded_score), \"topk\": expanded_hits},\n",
    "        \"pred_intent_for_eval\": pred_intent_for_eval,\n",
    "        \"answer\": answer,\n",
    "        \"confidence\": confidence\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb05c65b-ac7f-4154-b1c8-faeae4b07410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " • ./artifacts/intent_clf_tfidf_lr.joblib\n",
      " • ./artifacts/retr_vectorizer.joblib\n",
      " • ./artifacts/kb_qa.joblib\n",
      " • ./artifacts/meta.json\n",
      " • ./artifacts/working_full.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 💾 Cell 12 — Save Artifacts\n",
    "# ----------------------------\n",
    "# What/Why:\n",
    "# - Persist final model & assets to ./artifacts so you can load them next time\n",
    "# - Includes: classifier pipeline, retrieval vectorizer, KB (Q/A/intent), metadata\n",
    "# ----------------------------\n",
    "\n",
    "import json\n",
    "from joblib import dump\n",
    "\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Final intent classifier pipeline\n",
    "clf_path = os.path.join(ARTIFACT_DIR, \"intent_clf_tfidf_lr.joblib\")\n",
    "dump(clf_pipeline, clf_path)\n",
    "\n",
    "# 2) Retrieval vectorizer (fit on ALL KB_Q)\n",
    "retr_path = os.path.join(ARTIFACT_DIR, \"retr_vectorizer.joblib\")\n",
    "dump(retr_vectorizer, retr_path)\n",
    "\n",
    "# 3) Knowledge base (original answers, cleaned questions, intents)\n",
    "kb_obj = {\"KB_Q\": KB_Q, \"KB_A\": KB_A, \"KB_I\": KB_I}\n",
    "kb_path = os.path.join(ARTIFACT_DIR, \"kb_qa.joblib\")\n",
    "dump(kb_obj, kb_path)\n",
    "\n",
    "# 4) Metadata: thresholds, classes, counts\n",
    "meta = {\n",
    "    \"intent_threshold\": float(INTENT_THRESHOLD),\n",
    "    \"retrieval_threshold\": float(RETR_THRESHOLD),\n",
    "    \"topk_default\": int(TOPK_DEFAULT),\n",
    "    \"n_rows\": int(len(df)),\n",
    "    \"n_classes\": int(df[\"intent\"].nunique()),\n",
    "    \"classes\": list(clf_pipeline.named_steps[\"clf\"].classes_)\n",
    "}\n",
    "meta_path = os.path.join(ARTIFACT_DIR, \"meta.json\")\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 5) (Optional) Keep a copy of the working dataframe for reference\n",
    "df.to_csv(os.path.join(ARTIFACT_DIR, \"working_full.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" •\", clf_path)\n",
    "print(\" •\", retr_path)\n",
    "print(\" •\", kb_path)\n",
    "print(\" •\", meta_path)\n",
    "print(\" •\", os.path.join(ARTIFACT_DIR, 'working_full.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07fc2a11-766d-42bb-a427-9f54e9b3d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reloaded artifacts.\n",
      "• Rows: 195 • Classes: 96\n",
      "• Thresholds: {'intent': 0.35, 'retrieval': 0.25, 'topk': 3}\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 📦 Cell 13 — Reload Artifacts\n",
    "# ----------------------------\n",
    "# What/Why:\n",
    "# - Bring back the saved model, vectorizer, and KB from ./artifacts\n",
    "# - Recreate the KB_TFIDF matrix for retrieval\n",
    "# - Restore thresholds from meta.json\n",
    "# ----------------------------\n",
    "\n",
    "import json\n",
    "from joblib import load\n",
    "\n",
    "def load_artifacts(path=ARTIFACT_DIR):\n",
    "    clf = load(os.path.join(path, \"intent_clf_tfidf_lr.joblib\"))\n",
    "    retr_vec = load(os.path.join(path, \"retr_vectorizer.joblib\"))\n",
    "    kb = load(os.path.join(path, \"kb_qa.joblib\"))  # {\"KB_Q\", \"KB_A\", \"KB_I\"}\n",
    "    with open(os.path.join(path, \"meta.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return clf, retr_vec, kb, meta\n",
    "\n",
    "# Example: run this at the top of a NEW session (or now to verify)\n",
    "clf_pipeline, retr_vectorizer, kb_loaded, meta = load_artifacts()\n",
    "\n",
    "# Restore globals used by router/retrieval for convenience\n",
    "KB_Q = kb_loaded[\"KB_Q\"]\n",
    "KB_A = kb_loaded[\"KB_A\"]\n",
    "KB_I = kb_loaded[\"KB_I\"]\n",
    "KB_TFIDF = retr_vectorizer.fit_transform(KB_Q)  # safe: fits identically on same KB_Q\n",
    "\n",
    "# Restore thresholds (you can still override later)\n",
    "INTENT_THRESHOLD = float(meta.get(\"intent_threshold\", 0.50))\n",
    "RETR_THRESHOLD   = float(meta.get(\"retrieval_threshold\", 0.35))\n",
    "TOPK_DEFAULT     = int(meta.get(\"topk_default\", 3))\n",
    "\n",
    "print(\"✅ Reloaded artifacts.\")\n",
    "print(\"• Rows:\", meta.get(\"n_rows\"), \"• Classes:\", meta.get(\"n_classes\"))\n",
    "print(\"• Thresholds:\", {\"intent\": INTENT_THRESHOLD, \"retrieval\": RETR_THRESHOLD, \"topk\": TOPK_DEFAULT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b4e8cef-83b0-44f9-ae52-80ba6a789675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-check: OK ✅\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 💬 Cell 14 — Chat Loop + Self-Check\n",
    "# ----------------------------\n",
    "# What/Why:\n",
    "# - `self_check()` confirms classifier + retrieval + router run end-to-end\n",
    "# - `chat()` lets you talk to the bot in the notebook\n",
    "# ----------------------------\n",
    "\n",
    "def self_check():\n",
    "    issues = []\n",
    "    try:\n",
    "        _ = clf_pipeline.predict([\"test\"])\n",
    "    except Exception as e:\n",
    "        issues.append((\"Classifier\", str(e)))\n",
    "    try:\n",
    "        _ = retr_vectorizer.transform([\"test\"])\n",
    "        _ = KB_TFIDF.shape\n",
    "    except Exception as e:\n",
    "        issues.append((\"Retrieval index\", str(e)))\n",
    "    try:\n",
    "        _ = route_query(\"test question\", method=\"hybrid\", topk=3)\n",
    "    except Exception as e:\n",
    "        issues.append((\"Router\", str(e)))\n",
    "    return \"OK ✅\" if not issues else issues\n",
    "\n",
    "print(\"Self-check:\", self_check())\n",
    "\n",
    "def chat(intent_threshold=INTENT_THRESHOLD, retrieval_threshold=RETR_THRESHOLD, method=\"hybrid\", topk=TOPK_DEFAULT):\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            q = input(\"You: \").strip()\n",
    "        except EOFError:\n",
    "            break\n",
    "        if not q or q.lower() in (\"exit\",\"quit\",\"q\"):\n",
    "            break\n",
    "        out = route_query(q, intent_threshold, retrieval_threshold, method, topk)\n",
    "        print(\"\\n---\")\n",
    "        print(\"Route:\", out[\"route\"])\n",
    "        print(\"Intent:\", out[\"intent\"])\n",
    "        print(\"Confidence:\", round(out[\"confidence\"], 3))\n",
    "        print(\"Answer:\", out[\"answer\"] if out[\"answer\"] else \"[No confident match — please rephrase]\")\n",
    "        print(\"Top matches (scores):\", [ (h['score'], h['question']) for h in out['retrieval']['topk'] ])\n",
    "        print(\"---\\n\")\n",
    "\n",
    "# Run if you want to chat now:\n",
    "# chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e20fc5b-19ac-4a15-90e8-699cd9dbfde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can I carry extra luggage?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Route: retrieval\n",
      "Intent: {'label': None, 'score': 0.0}\n",
      "Confidence: 0.355\n",
      "Answer: Airport and pre-booking charges for excess check-in baggage are listedhere.\n",
      "Top matches (scores): [(0.35521286328708845, 'what are the charges for excess check-in baggage'), (0.35521286328708845, 'what are the charges for excess check-in baggage'), (0.34880199386570054, 'can excess baggage be pre-purchased')]\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  liquor?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Route: retrieval\n",
      "Intent: {'label': None, 'score': 0.0}\n",
      "Confidence: 0.795\n",
      "Answer: Maximum of 5 liters of alcoholic beverages with alcohol content between 24% and 70% by volume is permitted in retail packaging as checked-in baggage.The permissible limit of 5 lt. includes the duty paid alcohol that passenger may buy from the airport. Bills for such purchases must always be kept handy.On a domestic flight, alcoholic beverages are only permitted to be carried as checked-in baggage, unless they are purchased from the duty paid outlets. These duty paid alcoholic beverages can then be carried as cabin baggage.Alcoholic beverages carried on-board by passengers are not permitted to be opened and/or consumed inside an aircraft.Carrying alcoholic beverages from/into the states of Bihar, Gujarat, Tripura, Mizoram, Nagaland, UT Lakshadweep or any state considered as a ‘dry state’ is not permitted.\n",
      "Top matches (scores): [(0.7951537859970181, 'can i carry my liquor'), (0.7951537859970181, 'can i carry my liquor'), (0.4279993749429476, 'can i carry duty free liquor in my hand baggage on my o d connection')]\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  travel certificate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Route: retrieval\n",
      "Intent: {'label': None, 'score': 0.0}\n",
      "Confidence: 0.941\n",
      "Answer: A travel certificate is a document that serves as proof of travel that you have completed. This document can be helpful in regards to reimbursements, LTC and GST claims, etc.\n",
      "Top matches (scores): [(0.9406339030935356, 'what is a travel certificate'), (0.9406339030935356, 'what is a travel certificate'), (0.9406339030935356, 'what is a travel certificate')]\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  food?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Route: retrieval\n",
      "Intent: {'label': None, 'score': 0.0}\n",
      "Confidence: 0.376\n",
      "Answer: Variety of hot meals, sandwiches, chef's choices, and special meals such as meals for diabetics, jain meal, low-calorie salads etc., are available for pre-booking at discounted rates. In addition to these, passengers can also pre-book Cake (Mocha, 500 g) to surprise their loved ones. All meals can be pre-booked up to 6 hours prior to departure, apart from special meals and cake which are available for pre-booking up to 24 hrs prior and 48 hours prior to departure, respectively.Our on-board menu offers a variety of ready-to-eat products, munchies and beverages to choose from.The images of F&B products featured across our platforms, including packaging, are for illustrative purposes only.\n",
      "Top matches (scores): [(0.3764424282478896, 'does spicejet provide any food or drinks onboard'), (0.3764424282478896, 'does spicejet provide any food or drinks onboard'), (0.01815058936035957, 'can i get a refund for the fee paid for my travel certificate')]\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Route: abstain\n",
      "Intent: {'label': None, 'score': 0.0}\n",
      "Confidence: 0.111\n",
      "Answer: [No confident match — please rephrase]\n",
      "Top matches (scores): [(0.11129293183050866, 'which credit/debit cards are accepted by spicejet for payment'), (0.10030067881232725, 'i have recently recovered from covid-19. can i travel by air'), (0.0, 'what is it like to fly with spicejet')]\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241be51d-158c-4d17-9327-92f5908a7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.872\n",
      "Macro F1:   0.695\n",
      "Weighted F1:0.839\n",
      "\n",
      "Per-class report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               abstain       0.00      0.00      0.00         0\n",
      "           booking_faq       0.98      0.95      0.96        43\n",
      "           general_faq       1.00      0.97      0.98        31\n",
      "intent_from_answer_000       0.50      1.00      0.67         2\n",
      "intent_from_answer_001       1.00      1.00      1.00         1\n",
      "intent_from_answer_002       0.00      0.00      0.00         1\n",
      "intent_from_answer_003       1.00      1.00      1.00         1\n",
      "intent_from_answer_004       1.00      1.00      1.00         1\n",
      "intent_from_answer_005       0.00      0.00      0.00         1\n",
      "intent_from_answer_006       0.50      1.00      0.67         1\n",
      "intent_from_answer_007       1.00      1.00      1.00         1\n",
      "intent_from_answer_008       1.00      1.00      1.00         1\n",
      "intent_from_answer_009       1.00      1.00      1.00         1\n",
      "intent_from_answer_010       1.00      1.00      1.00         1\n",
      "intent_from_answer_011       1.00      1.00      1.00         1\n",
      "intent_from_answer_012       1.00      1.00      1.00         1\n",
      "intent_from_answer_013       1.00      1.00      1.00         1\n",
      "intent_from_answer_014       1.00      1.00      1.00         1\n",
      "intent_from_answer_015       1.00      1.00      1.00         1\n",
      "intent_from_answer_016       1.00      1.00      1.00         1\n",
      "intent_from_answer_017       1.00      1.00      1.00         2\n",
      "intent_from_answer_018       0.50      1.00      0.67         1\n",
      "intent_from_answer_019       0.00      0.00      0.00         1\n",
      "intent_from_answer_020       1.00      1.00      1.00         1\n",
      "intent_from_answer_021       0.50      1.00      0.67         1\n",
      "intent_from_answer_022       0.50      1.00      0.67         1\n",
      "intent_from_answer_023       0.00      0.00      0.00         1\n",
      "intent_from_answer_024       1.00      1.00      1.00         2\n",
      "intent_from_answer_025       0.00      0.00      0.00         1\n",
      "intent_from_answer_026       0.50      1.00      0.67         1\n",
      "intent_from_answer_027       1.00      1.00      1.00         1\n",
      "intent_from_answer_028       1.00      1.00      1.00         1\n",
      "intent_from_answer_029       0.50      1.00      0.67         1\n",
      "intent_from_answer_030       0.00      0.00      0.00         1\n",
      "intent_from_answer_031       0.00      0.00      0.00         1\n",
      "intent_from_answer_032       0.50      1.00      0.67         1\n",
      "intent_from_answer_033       0.50      1.00      0.67         1\n",
      "intent_from_answer_034       0.00      0.00      0.00         1\n",
      "intent_from_answer_035       0.50      1.00      0.67         1\n",
      "intent_from_answer_036       0.00      0.00      0.00         1\n",
      "intent_from_answer_037       0.50      1.00      0.67         1\n",
      "intent_from_answer_038       0.00      0.00      0.00         1\n",
      "intent_from_answer_039       1.00      1.00      1.00         2\n",
      "intent_from_answer_040       0.50      1.00      0.67         1\n",
      "intent_from_answer_041       0.00      0.00      0.00         1\n",
      "intent_from_answer_042       1.00      1.00      1.00         1\n",
      "intent_from_answer_043       1.00      1.00      1.00         1\n",
      "intent_from_answer_044       0.50      1.00      0.67         1\n",
      "intent_from_answer_045       0.00      0.00      0.00         1\n",
      "intent_from_answer_046       0.50      1.00      0.67         1\n",
      "intent_from_answer_047       1.00      1.00      1.00         1\n",
      "intent_from_answer_048       1.00      1.00      1.00         1\n",
      "intent_from_answer_049       1.00      1.00      1.00         1\n",
      "intent_from_answer_050       1.00      1.00      1.00         1\n",
      "intent_from_answer_051       1.00      1.00      1.00         1\n",
      "intent_from_answer_052       1.00      1.00      1.00         1\n",
      "intent_from_answer_053       0.50      1.00      0.67         1\n",
      "intent_from_answer_054       1.00      1.00      1.00         2\n",
      "intent_from_answer_055       1.00      1.00      1.00         1\n",
      "intent_from_answer_056       1.00      1.00      1.00         1\n",
      "intent_from_answer_057       1.00      1.00      1.00         2\n",
      "intent_from_answer_058       1.00      1.00      1.00         1\n",
      "intent_from_answer_059       1.00      1.00      1.00         1\n",
      "intent_from_answer_060       1.00      1.00      1.00         1\n",
      "intent_from_answer_061       0.00      0.00      0.00         1\n",
      "intent_from_answer_062       0.50      1.00      0.67         1\n",
      "intent_from_answer_063       1.00      1.00      1.00         1\n",
      "intent_from_answer_064       1.00      1.00      1.00         1\n",
      "intent_from_answer_065       1.00      1.00      1.00         1\n",
      "intent_from_answer_066       1.00      1.00      1.00         1\n",
      "intent_from_answer_067       1.00      1.00      1.00         1\n",
      "intent_from_answer_068       1.00      1.00      1.00         1\n",
      "intent_from_answer_069       1.00      1.00      1.00         1\n",
      "intent_from_answer_070       1.00      1.00      1.00         1\n",
      "intent_from_answer_071       0.00      0.00      0.00         1\n",
      "intent_from_answer_072       0.50      1.00      0.67         1\n",
      "intent_from_answer_073       0.50      1.00      0.67         1\n",
      "intent_from_answer_074       0.00      0.00      0.00         1\n",
      "intent_from_answer_075       0.00      0.00      0.00         1\n",
      "intent_from_answer_076       1.00      1.00      1.00         2\n",
      "intent_from_answer_077       1.00      1.00      1.00         1\n",
      "intent_from_answer_078       1.00      1.00      1.00         2\n",
      "intent_from_answer_079       0.00      0.00      0.00         1\n",
      "intent_from_answer_080       1.00      1.00      1.00         2\n",
      "intent_from_answer_081       0.00      0.00      0.00         1\n",
      "intent_from_answer_082       0.50      1.00      0.67         1\n",
      "intent_from_answer_083       1.00      1.00      1.00         2\n",
      "intent_from_answer_084       1.00      1.00      1.00         1\n",
      "intent_from_answer_085       1.00      1.00      1.00         1\n",
      "intent_from_answer_086       0.50      1.00      0.67         1\n",
      "intent_from_answer_087       0.00      0.00      0.00         1\n",
      "intent_from_answer_088       0.00      0.00      0.00         1\n",
      "intent_from_answer_089       0.50      1.00      0.67         1\n",
      "intent_from_answer_090       1.00      1.00      1.00         2\n",
      "intent_from_answer_091       0.00      0.00      0.00         1\n",
      "intent_from_answer_092       0.33      1.00      0.50         1\n",
      " specialAssistance_faq       1.00      0.94      0.97        17\n",
      "\n",
      "              accuracy                           0.87       195\n",
      "             macro avg       0.66      0.77      0.70       195\n",
      "          weighted avg       0.83      0.87      0.84       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# ✅ Bot accuracy on your current dataset (single cell)\n",
    "# - Uses the router's predicted intent label (or \"abstain\")\n",
    "# - Works with the globals you already have: INTENT_THRESHOLD, RETR_THRESHOLD, TOPK_DEFAULT\n",
    "# ----------------------------\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 1) Inputs\n",
    "X_test = df[\"question_clean\"].astype(str).tolist()\n",
    "y_true = df[\"intent\"].astype(str).tolist()\n",
    "\n",
    "# 2) Predict with the actual bot logic\n",
    "y_pred = []\n",
    "for q in X_test:\n",
    "    out = route_query(\n",
    "        q,\n",
    "        intent_threshold=INTENT_THRESHOLD,\n",
    "        retrieval_threshold=RETR_THRESHOLD,\n",
    "        method=\"hybrid\",\n",
    "        topk=TOPK_DEFAULT\n",
    "    )\n",
    "    # Use the router's final intent choice for evaluation\n",
    "    # (falls back to \"abstain\" if the bot abstains)\n",
    "    pred_label = out.get(\"pred_intent_for_eval\") or \"abstain\"\n",
    "    y_pred.append(str(pred_label))\n",
    "\n",
    "# 3) Metrics (treat \"abstain\" as a class so it's counted)\n",
    "labels_full = sorted(list(set(y_true) | {\"abstain\"}))\n",
    "\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "f1_m  = f1_score(y_true, y_pred, average=\"macro\", labels=labels_full)\n",
    "f1_w  = f1_score(y_true, y_pred, average=\"weighted\", labels=labels_full)\n",
    "\n",
    "print(f\"Accuracy:   {acc:.3f}\")\n",
    "print(f\"Macro F1:   {f1_m:.3f}\")\n",
    "print(f\"Weighted F1:{f1_w:.3f}\\n\")\n",
    "\n",
    "print(\"Per-class report:\")\n",
    "print(classification_report(y_true, y_pred, labels=labels_full, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e0c01-d352-469d-8f8b-87449ac66ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
